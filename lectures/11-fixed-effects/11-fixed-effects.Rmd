---
title: Data Science for Economists
subtitle: Fixed Effects - control for what you can't see
author: Kyle Coombs
date: "Bates College | [ECON/DCS 368](https://github.com/big-data-and-economics)"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts,css/my-css.css] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
---
name: toc

```{css, echo=FALSE}
@media print {
  .has-continuation {
    display: block !important;
  }
}
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(
  #comment = "#>",
  fig.align='center', fig.width=4.5, fig.height=2.75,
  dpi=300, #fig.path='Figs/',
  cache=F, warning=F, message=F
  )

#knitr::opts_chunk$set(dev = "svg")

devtools::install_github("dill/emoGG")
library(pacman)
p_load(
  broom, here, tidyverse,janitor,
  emoGG, latex2exp, ggplot2, ggthemes, viridis, extrafont, gridExtra,
  kableExtra,
  data.table,
  dplyr,
  lubridate,
  magrittr, knitr, parallel,
  transformr,
  wooldridge,
  gganimate, fixest, magick, scales, Cairo
)
# Define pink color
red_pink <- "#e64173"
turquoise <- "#20B2AA"
grey_light <- "grey70"
grey_mid <- "grey50"
grey_dark <- "grey20"
purple <- "#6A5ACD"
# Dark slate grey: #314f4f
# Knitr options
# A blank theme for ggplot
theme_empty <- theme_bw() + theme(
  line = element_blank(),
  rect = element_blank(),
  strip.text = element_blank(),
  axis.text = element_blank(),
  plot.title = element_blank(),
  axis.title = element_blank(),
  plot.margin = structure(c(0, 0, -0.5, -1), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none"
)
theme_simple <- theme_bw() + theme(
  line = element_blank(),
  panel.grid = element_blank(),
  rect = element_blank(),
  strip.text = element_blank(),
  axis.text.x = element_text(size = 18, family = "STIXGeneral"),
  axis.text.y = element_blank(),
  axis.ticks = element_blank(),
  plot.title = element_blank(),
  axis.title = element_blank(),
  # plot.margin = structure(c(0, 0, -1, -1), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none"
)
theme_axes_math <- theme_void() + theme(
  text = element_text(family = "MathJax_Math"),
  axis.title = element_text(size = 22),
  axis.title.x = element_text(hjust = .95, margin = margin(0.15, 0, 0, 0, unit = "lines")),
  axis.title.y = element_text(vjust = .95, margin = margin(0, 0.15, 0, 0, unit = "lines")),
  axis.line = element_line(
    color = "grey70",
    size = 0.25,
    arrow = arrow(angle = 30, length = unit(0.15, "inches")
  )),
  plot.margin = structure(c(1, 0, 1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none"
)
theme_axes_serif <- theme_void() + theme(
  text = element_text(family = "MathJax_Main"),
  axis.title = element_text(size = 22),
  axis.title.x = element_text(hjust = .95, margin = margin(0.15, 0, 0, 0, unit = "lines")),
  axis.title.y = element_text(vjust = .95, margin = margin(0, 0.15, 0, 0, unit = "lines")),
  axis.line = element_line(
    color = "grey70",
    size = 0.25,
    arrow = arrow(angle = 30, length = unit(0.15, "inches")
  )),
  plot.margin = structure(c(1, 0, 1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none"
)
theme_axes <- theme_void() + theme(
  axis.title = element_text(size = 18),
  axis.title.x = element_text(hjust = .95, margin = margin(0.15, 0, 0, 0, unit = "lines")),
  axis.title.y = element_text(vjust = .95, margin = margin(0, 0.15, 0, 0, unit = "lines")),
  axis.line = element_line(
    color = grey_light,
    size = 0.25,
    arrow = arrow(angle = 30, length = unit(0.15, "inches")
  )),
  plot.margin = structure(c(1, 0, 1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none"
)
theme_metro_regtitle <- function(x) {
  theme_classic() + 
  theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
        plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
        text = element_text(size=10),
        axis.title = element_text(size=10),
        axis.title.x= element_text(size=10),
        axis.title.y= element_text(size=10))
}

mw_states <-  c("MA", "VT", "ME",'NH','RI','CT')

color_values <- c('black','blue','red','purple','green','cyan')

# theme_set(theme_gray(base_size = 20))
```

# Table of contents

- [Prologue](#prologue)

- [Causal Inference Review](#causal-inference-review)

- [Fixed Effects](#fixed-effects)
  - [Panel Data](#panel-data)
  - [Crime and Arrests](#crime-and-arrests)

- [Implementation](#implementation)
  - [De-meaning](#demeaning)
  - [Least Squares Dummy Variable](#lsdv)

---
name: prologue
class: inverse, center, middle
# Prologue

---

# Prologue

- We see in the Opportunity Atlas that neighborhood income mobility is correlated with many outcomes 

- But are any of these correlations .pink[causal]?

- If so, we should be able to .pink[change] neighborhood characteristics to .pink[change] outcomes

- Problem set 3 has been posted to the course website, get started early! 

---

# Goals today

1. Review omitted variable bias
2. Introduce fixed effects
3. Go over an example
4. Play with fixed effects in R

---
# Attribution

- These slides are adapted from work by Nick Huntington-Klein and Ed Rubin

- They're both superb econometric instructors and I highly recommend their work

---
# Questions?

- Problem set issues?

- Clarifications on final project?

- Clarifications on hack-a-thon?

- Anything else? 

---
class: inverse, center, middle
name: omitted-variable-bias

# Omitted Variable Bias

---
# Causal Inference Review

- Last week, we discussed .hi[omitted variable bias].

- We worked through using control variables to isolate the relation between our treatment and our outcome.

- [Can anyone define endogeneity for me?](https://www.mentimeter.com/app/presentation/bly9ptimf8urion84gscyfad8xz76mje/38559f6owyaf)

--

- $cov(X,\varepsilon) = 0$

- No relationship between the error term and the independent variable

---
# Forms of endogeneity

1. Reverse causality: $X \rightarrow Y$ but also $Y \rightarrow X$

2. Selection bias: $X \rightarrow Y$ but also $Z \rightarrow X$ and $Z \rightarrow Y$

3. Omitted variable bias: $X \rightarrow Y$ but also $Z \rightarrow Y$

4. Measurement error: $X \rightarrow Y$ but also $X \rightarrow \hat{X}$ (this one is a little different, but it's still a form of endogeneity)

---
# Conditional Independence Assumption

- Last week we also talked about conditional independence assumption

--

- After controlling for all the variables that are correlated with both the treatment and the outcome, the treatment is independent of the error term

- This is a way to minimize selection bias/omitted variable bias

- But what if we miss a variable in our model?

- What if we know a variable, but we cannot measure it?

- Any guesses? 

---
# You cannot measure what you cannot see

- What if our data vary by time and individual and our regression model is:

$$
\begin{align}
  Earnings &= \beta_0 + \beta_1 Edu + \beta_2 Ability + \beta_3 Experience + \cdots + \\
  &\beta_{k-2} ParentAttentive + \beta_{k-1} Race + \beta_k Gender + u 
\end{align}
$$

- ParentAttentive captures how attentive a child's parents are, which definitely matters to upbringing

- We probably do not have data on parental attention or ability, but we know they matter

- So the regression we run is

$$
\begin{align}
  Earnings &= \beta_0 + \beta_1 Edu + \beta_2 Race + \beta_3 Experience \cdots + \\
  & + \beta_k Gender +(\beta_{k-1} Ability + \beta_k ParentAttentive + u)
\end{align}
$$

- But after childhood, parental attention is fixed and ability is slow to change

- How can we control for them? 

---

# Causal Inference Unit

- Much of causal inference is focused on *finding ways to control for stuff that we can't measure*

- Seems impossible! But it is possible, at least in some circumstances

- Today, we will be talking about *within variation* and *between variation*, and the ability to control for all *between variation* using *fixed effects*

---
# Control John Cena

```{r, out.width="800px",fig.cap="John Cena cannot hide from fixed effects.",echo=FALSE}
knitr::include_graphics("https://media1.tenor.com/m/IQ5zuNhltCEAAAAC/john-cena-you-cant-see-me.gif")
```

---
name: fixed-effects
class: inverse, center, middle
# Fixed Effects

---
# Fixed effects

- Fixed effects are a way to control for .hi[endogeneity]

- Within a **group of observations**, or **dimension**, we remove the within-group averages from the data

- A group could be a person, a company, a state, a country, a time period, etc. -- you just need multiple observations within the group

- Any leftover variation in the data is not related to difference between groups

- This is all based on the Frisch-Waugh-Lovell theorem, which we won't cover in this class -- but it is neat! 

- They are incredibly powerful for taking big steps towards causal inference and for simplifying big, multi-dimensional data

---
name: panel-data
# Panel Data

- We are working in the domain of *panel data*

- Panel data is when you observe the same individual over multiple periods

- "Individual" could be a person, or a company, or a state, or a country, etc. There are $N$ individuals in the panel data

- "Time period" could be a year, a month, a day, etc.. There are $T$ time periods in the data

- For now we'll assume we observe each individual the same number of times, i.e. a *balanced* panel (so we have $N\times T$ observations)

- This works with unbalanced panels too, but it's more complicated


---
# Panel Data

- Here's what (a few rows from) a panel data set looks like - a variable for individual (county), a variable for time (year), and then the data

```{r,eval=FALSE}
data(crime4)
crime4 %>%
  select(county, year, crmrte, prbarr) %>%
  rename(County = county,
         Year = year,
         CrimeRate = crmrte,
         ProbofArrest = prbarr) %>%
  slice(1:9) %>%
  knitr::kable(note = '...') %>%
  kableExtra::add_footnote('9 rows out of 630. "Prob. of Arrest" is estimated probability of being arrested when you commit a crime', notation = 'none')
```


---
# Panel Data

- Here's what (a few rows from) a panel data set looks like - a variable for individual (county), a variable for time (year), and then the data

```{r, dev = 'CairoPNG',echo=FALSE}
data(crime4)
crime4 %>%
  select(county, year, crmrte, prbarr) %>%
  rename(County = county,
         Year = year,
         CrimeRate = crmrte,
         ProbofArrest = prbarr) %>%
  slice(1:9) %>%
  knitr::kable(note = '...') %>%
  kableExtra::add_footnote('9 rows out of 630. "Prob. of Arrest" is estimated probability of being arrested when you commit a crime', notation = 'none')
```

---
name: crime-and-arrests
# Crime and Arrests

- Let's ask how increased probability of arrest affects crime

- Certainly we'd expect there to be correlation between the two!

- Why can't we just estimate this regression?

$$\text{Crime Rate} = \beta_0 + \beta_1 \text{Prob. of Arrest} + \epsilon$$

--

1. Reverse causality -- more crime leads to more arrests

2. Selection bias -- counties with more crime might institute 

3. Omitted variable bias -- counties with higher property values may have higher crime rates, but also more tax revenue to spend on police

Do you notice that these problems have overlap? That's cause they're all forms of .hi[endogeneity!]

---
# Between and Within

- Let's pick a few counties and graph this out

```{r, dev = 'CairoPNG',echo=FALSE}
crime4 %>% 
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  group_by(county) %>%
  mutate(label = case_when(
    crmrte == max(crmrte) ~ paste('County',county),
    TRUE ~ NA_character_
  )) %>%
  ggplot(aes(x =  prbarr, y = crmrte, color = factor(county), label = label)) + 
  geom_point() + 
  geom_text(hjust = -.1, size = 14/.pt) + 
  theme_metro_regtitle() + 
  labs(x = 'Probability of Arrest', 
       y = 'Crime Rate',
       caption = 'One outlier eliminated in County 7.') + 
  #scale_x_continuous(limits = c(.15, 2.5)) + 
  guides(color = FALSE, label = FALSE) + 
  scale_color_manual(values = c('black','blue','red','purple'))
```

---

# Between and Within

- If we look at the overall variation, just pretending this is all together, we get this

```{r, dev = 'CairoPNG',echo=FALSE}
crime4 %>% 
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  group_by(county) %>%
  mutate(label = case_when(
    crmrte == max(crmrte) ~ paste('County',county),
    TRUE ~ NA_character_
  )) %>%
  ggplot(aes(x =  prbarr, y = crmrte, color = factor(county), label = label)) + 
  geom_point() + 
  geom_text(hjust = -.1, size = 14/.pt) + 
  theme_metro_regtitle() + 
  labs(x = 'Probability of Arrest', 
       y = 'Crime Rate',
       caption = 'One outlier eliminated in County 7.') + 
  #scale_x_continuous(limits = c(.15, 2.5)) + 
  guides(color = FALSE, label = FALSE) + 
  scale_color_manual(values = c('black','blue','red','purple')) + 
  geom_smooth(method = 'lm', aes(color = NULL, label = NULL), se = FALSE)
```


---
# Between and Within

- BETWEEN variation is what we get if we look at the relationship between the *means of each county*

```{r, dev = 'CairoPNG',echo=FALSE}
crime4 %>% 
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  group_by(county) %>%
  mutate(label = case_when(
    crmrte == max(crmrte) ~ paste('County',county),
    TRUE ~ NA_character_
  ),
  mcrm = mean(crmrte),
  mpr = mean(prbarr)) %>%
  ggplot(aes(x =  prbarr, y = crmrte, color = factor(county), label = label)) + 
  geom_point() + 
  geom_text(hjust = -.1, size = 14/.pt) + 
  theme_metro_regtitle() + 
  labs(x = 'Probability of Arrest', 
       y = 'Crime Rate',
       caption = 'One outlier eliminated in County 7.') + 
  #scale_x_continuous(limits = c(.15, 2.5)) + 
  guides(color = FALSE, label = FALSE) + 
  scale_color_manual(values = c('black','blue','red','purple')) + 
  geom_point(aes(x = mpr, y = mcrm), size = 20, shape = 3, color = 'darkorange') + 
  annotate(geom = 'text', x = .3, y = .02, label = 'Means Within Each County', color = 'darkorange', size = 14/.pt)
```

---

# Between and Within

- And I mean it! Only look at those means! Individual year-to-year variation within county doesn't matter.

```{r, dev = 'CairoPNG',echo=FALSE}
crime4 %>% 
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  group_by(county) %>%
  mutate(label = case_when(
    crmrte == max(crmrte) ~ paste('County',county),
    TRUE ~ NA_character_
  ),
  mcrm = mean(crmrte),
  mpr = mean(prbarr)) %>%
  ggplot(aes(x =  prbarr, y = crmrte, color = factor(county), label = label)) + 
  #geom_point() + 
  #geom_text(hjust = -.1, size = 14/.pt) + 
  theme_metro_regtitle() + 
  labs(x = 'Probability of Arrest', 
       y = 'Crime Rate',
       caption = 'One outlier eliminated in County 7.') + 
  #scale_x_continuous(limits = c(.15, 2.5)) + 
  guides(color = FALSE, label = FALSE) + 
  scale_color_manual(values = c('black','blue','red','purple')) + 
  geom_point(aes(x = mpr, y = mcrm), size = 20, shape = 3, color = 'darkorange') + 
  geom_smooth(aes(color = NULL), method = 'lm', se = FALSE)+
  annotate(geom = 'text', x = .3, y = .02, label = 'OLS Fit on These Four Points', color = 'blue', size = 14/.pt)
```

---

# Between and Within

- Within variation treats the orange crosses as individualized axes for the variation *within* county from year-to-year only!

```{r, echo=FALSE}
cranim <- crime4 %>% 
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  mutate(allcrm = mean(crmrte),
         allmpr = mean(prbarr)) %>%
  group_by(county) %>%
  mutate(label = case_when(
    crmrte == max(crmrte) ~ paste('County',county),
    TRUE ~ NA_character_
  ),
  mcrm = mean(crmrte),
  mpr = mean(prbarr),
  stage = '1. Raw Data')
cranim <- cranim %>%
  bind_rows(cranim %>% 
              mutate(crmrte = crmrte - mcrm + allcrm,
                     prbarr = prbarr - mpr + allmpr,
                     mcrm = allcrm,
                     mpr = allmpr,
                     stage = '2. Remove all between variation'))

p <- ggplot(cranim, aes(x =  prbarr, y = crmrte, color = factor(county), label = label)) + 
  geom_point() + 
  geom_text(hjust = -.1, size = 14/.pt)  + 
  labs(x = 'Probability of Arrest', 
       y = 'Crime Rate',
       caption = 'One outlier eliminated in County 7.') + 
  #scale_x_continuous(limits = c(.15, 2.5)) + 
  guides(color = FALSE, label = FALSE) + 
  scale_color_manual(values = c('black','blue','red','purple')) + 
  geom_smooth(aes(color = NULL), method = 'lm', se = FALSE)+
  geom_point(aes(x = mpr, y = mcrm), size = 20, shape = 3, color = 'darkorange') + 
  transition_states(stage) + 
  theme_metro_regtitle()

animate(p, nframes = 80)

```

---

# Between and Within

- We can clearly see that *between counties* there's a strong positive relationship

- But if you look *within* counties, the relationship seems weakly negative

- Which would make sense - if you think your chances of getting arrested are high, that should be a deterrent to crime

- But what are we actually doing here? Let's think about the data-generating process!

- What goes into the probability of arrest and the crime rate? Lots of stuff!

---

# Between and Within

- For each of these variables we can ask if they vary *between counties* and/or *within counties*

- Lots of stuff like geography, landmarks, the quality of the schools only varies *between counties*, but not that much over the years

- The number of police on the streets, the poverty rate, and the probability of arrest, vary both *between* and *within* counties from year to year

- So county fixed effects sucks up all the variation for things that do not vary within counties

- That means even if we cannot measure some variable, if it only varies between counties, we can control for it!

---

# Between and Within

- Now the task of identifying ProbArrest $\rightarrow$ CrimeRate becomes much simpler!

- If we control for County, that cuts out tons of omitted variables

- Conveniently, we can control for County just like it was any other variable!

- And when we do, we automatically *control for all variables that only have between variation*, whatever they are, even if we can't measure them directly or didn't think about them

- *All that's left is the within variation*

---

# Concept Checks

- For each of these variables, would we expect them to have within variation, between variation, or both?

- Individual = person
  - How a child's height changes as they age.
  - In a data set tracking many people over many years, the variation in the number of children a person has over their lifetime.

- Individual = city
  -  Overall, Paris, France has more restaurants than Paris, Texas.

- Individual = genre
  - The average pop music album sells more copies than the average jazz album
  - Miles Davis' *Kind of Blue* sold very well *for a jazz album*.
  - Michael Jackson's *Thriller*, a pop album, sold many more copies than *Kind of Blue*, a jazz album.

---
name: implementation
class: inverse, center, middle

# Implementation

---

# Removing Between Variation

- Okay so that's the concept

- Remove all the between variation so that all that's left is within variation

- And in the process control for any variables that are made up only of between variation

- How can we actually do this? And what's really going on?

- Let's first talk about the regression model itself that this implies

- Then let's actually do the thing. There are two main ways: *de-meaning* and *binary variables* (they give the same result, for balanced panels anyway)

---

# Estimation vs. Design

- To be clear, this is *exactly 0% different* from what we've done before in terms of controlling for stuff

- And in fact we're about to do the *exact same thing we did before* by just adding a categorical control variable for `county` or whatever

- (and in fact the "within" thing holds with other categorical controls - a categorical control for education isolates variation "within education levels")

- The difference is the *reason we're doing it*. It's fixed effects because *a categorical control for individual controls for a lot of stuff*, and we think closes a *lot* of back doors for us, not just one, and not just ones we can measure

---
# The Model


The $it$ subscript says this variable varies over individual $i$ and time $t$

$$Y_{it} = \beta_0 + \beta_1 X_{it} + \varepsilon_{it}$$

- What if there are individual-level components in the error term causing omitted variable bias? 
- $X_{it}$ is related to LocalStuff which is not in the model and thus in the error term!
- Regular ol' omitted variable bias. If we don't adjust for the individual effect, we get a biased $\hat{\beta}_1$ 
- (this bias is called "pooling bias" although it's really just a form of omitted variable bias)
- We really have this then:

$$Y_{it} = \beta_0 + \beta_1 X_{it} + (\alpha_i + \varepsilon_{it})$$

---
name: demeaning
# De-meaning

- Let's do de-meaning first, since it's most closely and obviously related to the "removing between variation" explanation we've been going for
- The process here is simple!

1. For each variable $X_{it}$, $Y_{it}$, etc., get the mean value of that variable for each individual $\bar{X}_i, \bar{Y}_i$
2. Subtract out that mean to get residuals $(X_{it} - \bar{X}_i), (Y_{it} - \bar{Y}_i)$
3. Work with those residuals

- That's it!

---

# How does this work?

- That $\alpha_i$ term gets absorbed
- The residuals are, by construction, no longer related to the $\alpha_i$, so it no longer goes in the residuals!

$$(Y_{it} - \bar{Y}_i) = \beta_0 + \beta_1(X_{it} - \bar{X}_i) + \varepsilon_{it}$$

---

# Try it!

- We can use `group_by` to get means-within-groups and subtract them out

```{r, echo = TRUE,eval=FALSE}
# library(tidyverse)
data(crime4, package = 'wooldridge')
crime4 <- crime4 %>%
  # Filter to the data points from our graph
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  group_by(county) %>%
  mutate(demeaned_crime = crmrte - mean_crime,
         demeaned_prob = prbarr - mean_prob)
```


```{r, echo = FALSE}
data(crime4, package = 'wooldridge')
crime4 <- crime4 %>%
  # Filter to the data points from our graph
  filter(county %in% c(1,3,7, 23),
         prbarr < .5) %>%
  group_by(county) %>%
  mutate(mean_crime = mean(crmrte),
         mean_prob = mean(prbarr)) %>%
  mutate(demeaned_crime = crmrte - mean_crime,
         demeaned_prob = prbarr - mean_prob)
```

---

# And Regress!

```{r, echo = TRUE}
orig_data <- feols(crmrte ~ prbarr, data = crime4)
de_mean <- feols(demeaned_crime ~ demeaned_prob, data = crime4)
etable(orig_data, de_mean)
```

---

# Interpreting a Within Relationship

- How can we interpret that slope of `-0.03`?

- This is all *within variation* so our interpretation must be *within-county*

- So, "comparing a county in year A where its arrest probability is 1 (100 percentage points) higher than it is in year B, we expect the number of crimes per person to drop by .03"

- Or if we think we've causally identified it (and want to work on a more realistic scale), "raising the arrest probability by 1 percentage point in a county reduces the number of crimes per person in that county by .0003".

- We're basically "controlling for county" (and will do that explicitly in a moment)

- So your interpretation should think of it in that way - *holding county constant* i.e. *comparing two observations with the same value of county* i.e. *comparing a county to itself at a different point in time*


---

# Concept Checks

- Why does subtracting the within-individual mean of each variable "control for individual"?

- In a sentence, interpret the slope coefficient in the estimated model $(Y_{it} - \bar{Y}_i) = 2 + 3(X_{it} - \bar{X}_i)$ where $Y$ is "blood pressure", $X$ is "stress at work", and $i$ is an individual person

---
name: lsdv
# Least Squares Dummy Variables

- De-meaning the data isn't the only way to do it!

- You can also use the least squares dummy variable (LSDV) method

- We just treat "individual" like the categorical variable it is and add it as a control! 

- Again, the regression approach is exactly the same as with any categorical control, but the *research design* reason for doing it is different

---

# Let's do it!

```{r, echo = TRUE}
lsdv <- feols(crmrte ~ prbarr + factor(county), data = crime4)
etable(orig_data, de_mean, lsdv, keep = c('prbarr', 'demeaned_prob'))
```

---

# The same!

- The result is the same, as it should be

- Except for that $R^2$ - What is that "within R2"?

- Because de-meaning takes out the part explained by the fixed effects ( $\alpha_i$ ) *before* running the regression, while LSDV does it *in* the regression

- So the .94 is the portion of `crmrte` explained by `prbarr` *and* `county`, whereas the .21 is the "within - $R^2$ " - the portion of *the within variation* that's explained by `prbarr`

- Neither is wrong (and the .94 isn't "better"), they're just measuring different things

---

# Why LSDV?

- A benefit of the LSDV approach is that it calculates the fixed effects $\alpha_i$ for you
- We left those out of the table with the `coefs` argument of `export_summs` (we rarely want them) but here they are:

```{r}
lsdv
```

- Interpretation is exactly the same as with a categorical variable - we have an omitted county, and these show the difference relative to that omitted county

---

# Why LSDV?

- LSDV makes clear what's happening by creating a separate intercept for each county
- Graphically, de-meaning moves all the points together, while LSDV moves the line up and down to meet the points

```{r, dev = 'CairoPNG',echo=FALSE}
crime4 %>%
  ungroup() %>%
  mutate(pred = predict(lsdv)) %>%
  group_by(county) %>%
  mutate(label = case_when(
    crmrte == max(crmrte) ~ paste('County',county),
    TRUE ~ NA_character_
  )) %>%
  ggplot(aes(x =  prbarr, y = crmrte, color = factor(county), label = label)) + 
  geom_point() + 
  geom_text(hjust = -.1, size = 14/.pt) + 
  geom_line(aes(y = pred, group = county), color = 'blue') +
  theme_metro_regtitle() + 
  labs(x = 'Probability of Arrest', 
       y = 'Crime Rate',
       caption = 'One outlier eliminated in County 7.') + 
  #scale_x_continuous(limits = c(.15, 2.5)) + 
  guides(color = FALSE, label = FALSE) + 
  scale_color_manual(values = c('black','blue','red','purple'))
```

---

# Why Not LSDV?

- LSDV is computationally expensive

- If there are a lot of individuals, or big data, or if you have many sets of fixed effects (yes you can do more than just individual - we'll get to that next time!), it can be very slow

- Most professionally made fixed-effects commands use de-meaning, but then adjust the standard errors properly

- (They also leave the fixed effects coefficients off the regression table by default)

---

# Going Professional

- Applied researchers rarely do either of these, and rather will use a command specifically designed for fixed effects

- Like good ol' `feols()`! (what did you think the "fe" part stood for?)

- Note there are also functions in **fixest** that do fixed effects in non-linear models like logit, probit, or poisson regression (`feglm()` and `fepois()`)

- Plus, it clusters the standard errors by the first fixed effect by default, which we usually want!

---

# Going Professional

```{r, echo = TRUE}
library(fixest)
pro <- feols(crmrte ~ prbarr | county, data = crime4)
etable(de_mean, pro)
```

---

# Limits to Fixed Effects

- Okay! At this point we have the concept behind fixed effects, can execute them, and know what they're good for

- What aren't they good for?

1. They don't control for anything that has within variation
2. They control away *everything* that's between-only, so we can't see the effect of anything that's between-only ("effect of geography on crime rate?" Nope!)
3. Anything with only a *little* within variation will have most of its variation washed out too ("effect of population density on crime rate?" probably not)
4. The estimate pays the most attention to individuals with *lots of variation in treatment*

- 2 and 3 can be addressed by using "random effects" instead but we aren't covering that in this class (see the The Effect chapter on Fixed Effects for more)

---
# Is this causal?

- After controlling for everything within county, is this causal?

--

- Probably not! Why not?

--

#### Within variation persists

1. Within-county time variation: maybe crime and arrest probability moved together (e.g. a crime wave)

2. Reverse causality: maybe officers respond to crime rates by changing their arrest effort

3. Omitted variable bias: maybe poverty or population density is driving both crime and arrest probability and changes over time

---

# Concept Checks

- Why can't we use individual-person fixed effects to study the impact of race on traffic stops?

- In a sentence, interpret the slope coefficient in the estimated model $(Y_{it} - \bar{Y}_i) = 1 + .5(X_{it} - \bar{X}_i)$ where $Y$ is "school funding per child" and $X$ is "population growth", and $i$ is city

---
class: inverse, center, middle

# Next lecture: Difference-in-differences
<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>

```{r gen_pdf, include = FALSE, cache = FALSE, eval = TRUE}
infile=knitr::current_input() %>% stringr::str_replace('.Rmd', '.html')
#print(infile)
pagedown::chrome_print(input = infile, timeout = 100)
```


